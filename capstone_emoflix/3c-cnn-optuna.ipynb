{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport optuna\nimport itertools\nfrom collections import Counter\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import load_model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n\nimport numpy as np\n\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = '../input/fer2013clean/fer2013-clean/Training/'\ntest_dir = '../input/fer2013clean/fer2013-clean/PublicTest/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                                   horizontal_flip = True,\n                                   zoom_range= [0.8,  1.2],\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                  # rotation_range = 10\n                                  # brightness_range = [0.5,1]\n                                  ) #values lower than 1 darken the images\ntest_datagen  = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MixupImageDataGenerator():\n    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n        \"\"\"Constructor for mixup image data generator.\n        Arguments:\n            generator {object} -- An instance of Keras ImageDataGenerator.\n            directory {str} -- Image directory.\n            batch_size {int} -- Batch size.\n            img_height {int} -- Image height in pixels.\n            img_width {int} -- Image width in pixels.\n        Keyword Arguments:\n            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n            subset {str} -- 'training' or 'validation' if validation_split is specified in\n            `generator` (ImageDataGenerator).(default: {None})\n        \"\"\"\n\n        self.batch_index = 0\n        self.batch_size = batch_size\n        self.alpha = alpha\n\n        # First iterator yielding tuples of (x, y)\n        self.generator1 = generator.flow_from_directory(directory,\n                                                        target_size=(img_height, img_width),\n                                                        class_mode=\"categorical\",\n                                                        batch_size=batch_size,\n                                                        color_mode='rgb',\n                                                        shuffle=True,\n                                                        subset=subset)\n\n        # Second iterator yielding tuples of (x, y)\n        self.generator2 = generator.flow_from_directory(directory,\n                                                        target_size=(img_height, img_width),\n                                                        class_mode=\"categorical\",\n                                                        batch_size=batch_size,\n                                                        color_mode='rgb',\n                                                        shuffle=True,\n                                                        subset=subset)\n\n        # Number of images across all classes in image directory.\n        self.n = self.generator1.samples\n\n    def reset_index(self):\n        \"\"\"Reset the generator indexes array.\n        \"\"\"\n\n        self.generator1._set_index_array()\n        self.generator2._set_index_array()\n\n    def on_epoch_end(self):\n        self.reset_index()\n\n    def reset(self):\n        self.batch_index = 0\n\n    def __len__(self):\n        # round up\n        return (self.n + self.batch_size - 1) // self.batch_size\n\n    def get_steps_per_epoch(self):\n        \"\"\"Get number of steps per epoch based on batch size and\n        number of images.\n        Returns:\n            int -- steps per epoch.\n        \"\"\"\n\n        return self.n // self.batch_size\n\n    def __next__(self):\n        \"\"\"Get next batch input/output pair.\n        Returns:\n            tuple -- batch of input/output pair, (inputs, outputs).\n        \"\"\"\n\n        if self.batch_index == 0:\n            self.reset_index()\n\n        current_index = (self.batch_index * self.batch_size) % self.n\n        if self.n > current_index + self.batch_size:\n            self.batch_index += 1\n        else:\n            self.batch_index = 0\n\n\n        # Get a pair of inputs and outputs from two iterators.\n        X1, y1 = self.generator1.next()\n        X2, y2 = self.generator2.next()\n\n        # random sample the lambda value from beta distribution.\n        b = X1.shape[0]\n        l = np.random.beta(self.alpha, self.alpha, b)\n        X_l = l.reshape(b, 1, 1, 1)\n        y_l = l.reshape(b, 1)\n\n        # Perform the mixup.\n        X = X1 * X_l + X2 * (1 - X_l)\n        y = y1 * y_l + y2 * (1 - y_l)\n        \n        return X1, y1\n\n    def __iter__(self):\n        while True:\n            yield next(self)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create Training and Validation Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = MixupImageDataGenerator(generator=train_datagen,\n                                          directory=train_dir,\n                                          batch_size=64,\n                                          img_height=48,\n                                          img_width=48)\n                                          #color_mode='rgb',\n                                          #class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(48,48),\n                                                  class_mode='categorical',\n                                                  batch_size=1,\n                                                  color_mode='rgb',\n                                                  shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# setting optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"step_size_train=train_generator.n//train_generator.batch_size\nstep_size_test =test_generator.n//test_generator.batch_size\nstep_size_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_rate = 0.25\nlr = 0.0001\npenalty = 0.0001\nnum_classes = 7\n\n#define the CNN model\ndef create_model(num_layer, mid_units, num_filters,dropout_rate):\n    \n    model = Sequential()\n    model.add(Conv2D(filters=num_filters[0], kernel_size=(3, 3),\n                 activation=\"relu\",\n                 input_shape=(48, 48, 3)))\n    for i in range(1,num_layer):\n        model.add(Conv2D(filters=num_filters[i], kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(dropout_rate))\n    model.add(Flatten())\n    model.add(Dense(mid_units))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    print(\"Optimize Start\")\n    \n    #clear_session\n    keras.backend.clear_session()\n    \n    #number of the convolution layer\n    num_layer = trial.suggest_int(\"num_layer\", 2, 5)\n    \n    #number of the unit\n    mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 300, 100))\n    \n    #number of the each convolution layer filter\n    num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n    \n    #dropout_rate\n    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n    \n    model = create_model(num_layer, mid_units, num_filters,dropout_rate)\n    model.compile(optimizer=Adam(lr=0.0001), loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n    \n    history = model.fit_generator(train_generator,\n                                  steps_per_epoch=train_generator.get_steps_per_epoch(),\n                                  epochs = 40, \n                                  verbose=1,\n                                  validation_data = test_generator, \n                                  validation_steps = 3586)\n\n    \n    scores = model.evaluate(test_generator, steps=step_size_test)\n    print('accuracy={}'.format(*scores))\n    \n\n    return 1 - history.history[\"val_accuracy\"][-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to check optimized parameters\n\nstudy.best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to check the evaluation value after optimization\n\nstudy.best_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.trials","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}